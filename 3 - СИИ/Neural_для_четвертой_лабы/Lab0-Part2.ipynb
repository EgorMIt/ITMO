{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\theano\\configdefaults.py:560: UserWarning: DeprecationWarning: there is no c++ compiler.This is deprecated and with Theano 0.11 a c++ compiler will be mandatory\n",
      "  warnings.warn(\"DeprecationWarning: there is no c++ compiler.\"\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "#import os\n",
    "#os.environ['THEANO_FLAGS'] = \"device=cuda,force_device=True,floatX=float32\"\n",
    "#import theano\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.callbacks import Callback\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import *\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(y):\n",
    "    t = np.zeros((len(y), np.max(y) + 1))\n",
    "    t[np.arange(len(y)), y] = 1\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 10)\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  51 159 253 159  50   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  48 238 252 252 252 237   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  54 227 253 252 239 233 252  57   6   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  10  60 224 252 253 252 202  84 252\n",
      " 253 122   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0 163 252 252 252 253 252 252  96 189 253 167   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  51 238 253 253 190 114 253 228\n",
      "  47  79 255 168   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  48 238 252 252 179  12  75 121  21   0   0 253 243  50   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  38 165 253 233 208  84   0   0\n",
      "   0   0   0   0 253 252 165   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   7 178 252 240  71  19  28   0   0   0   0   0   0 253 252 195   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0  57 252 252  63   0   0   0\n",
      "   0   0   0   0   0   0 253 252 195   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0 198 253 190   0   0   0   0   0   0   0   0   0   0 255 253\n",
      " 196   0   0   0   0   0   0   0   0   0   0   0  76 246 252 112   0   0\n",
      "   0   0   0   0   0   0   0   0 253 252 148   0   0   0   0   0   0   0\n",
      "   0   0   0   0  85 252 230  25   0   0   0   0   0   0   0   0   7 135\n",
      " 253 186  12   0   0   0   0   0   0   0   0   0   0   0  85 252 223   0\n",
      "   0   0   0   0   0   0   0   7 131 252 225  71   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0  85 252 145   0   0   0   0   0   0   0  48 165\n",
      " 252 173   0   0   0   0   0   0   0   0   0   0   0   0   0   0  86 253\n",
      " 225   0   0   0   0   0   0 114 238 253 162   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0  85 252 249 146  48  29  85 178 225 253\n",
      " 223 167  56   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  85 252 252 252 229 215 252 252 252 196 130   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  28 199 252 252 253 252 252 233\n",
      " 145   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0  25 128 252 253 252 141  37   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "#PUT HERE DATA FROM https://keras.io/datasets/ \n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data() \n",
    "\n",
    "# flatten data\n",
    "x_train = x_train.reshape((x_train.shape[0], -1))\n",
    "x_test = x_test.reshape((x_test.shape[0], -1))\n",
    "\n",
    "# transform decimal to unitary code\n",
    "y_train = one_hot(y_train)\n",
    "y_test = one_hot(y_test)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(history):\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "style = {'description_width': 'initial'}\n",
    "@interact_manual(\n",
    "    n_layers=IntSlider(min=0, max=4, value=2, description='Layers: '),\n",
    "    layer_size=IntSlider(min=0, max=20, value=6, description='Neurons per layer: ', style=style),\n",
    "    layer1_type=Dropdown(options=['softmax', 'relu', 'tanh', 'sigmoid', 'linear'], value='relu',\n",
    "                          description='Layer 1 activation type: ', style=style),\n",
    "    layer2_type=Dropdown(options=['softmax', 'relu', 'tanh', 'sigmoid', 'linear'], value='relu',\n",
    "                          description='Layer 2 activation type ', style=style),\n",
    "    layer3_type=Dropdown(options=['softmax', 'relu', 'tanh', 'sigmoid', 'linear'], value='relu',\n",
    "                          description='Layer 3 activation type: ', style=style),\n",
    "    layer4_type=Dropdown(options=['softmax', 'relu', 'tanh', 'sigmoid', 'linear'], value='relu',\n",
    "                          description='Layer 4 activation type: ', style=style),\n",
    "    layer_out_type=Dropdown(options=['softmax', 'relu', 'tanh', 'sigmoid', 'linear'], value='sigmoid',\n",
    "                          description='Output layer activation type: ', style=style),\n",
    "    loss_func=Dropdown(options={\n",
    "        'Standard deviation': 'mse', \n",
    "        'Mean absolute deviation': 'mae',\n",
    "        'Binary crossentropy': 'binary_crossentropy',\n",
    "        'Categorical crossentropy': 'categorical_crossentropy'\n",
    "    }, value='categorical_crossentropy', description='Loss function: ', style=style),\n",
    "    batch_size = BoundedIntText(min=0, max=len(x_train), value=100, description='Batch size: ', style=style),\n",
    "    lr=ToggleButtons(options=[\"-0.1\", \"0\", \"0.001\", \"0.01\", \"0.05\", \"0.1\", \"0.5\", \"1\", \"5\"], \n",
    "                               value=\"0.01\", description='Learn rate: ', style=style),\n",
    "    l1=ToggleButtons(options=[\"-0.1\", \"0\", \"0.0001\", \"0.0005\", \"0.001\", \"0.005\", \"0.01\", \"0.05\", \"0.1\"], \n",
    "                               value=\"0.0001\", description='Regularization  L1: ', style=style),\n",
    "    l2=ToggleButtons(options=[\"-0.1\", \"0\", \"0.0001\", \"0.0005\", \"0.001\", \"0.005\", \"0.01\", \"0.05\", \"0.1\"], \n",
    "                               value=\"0.0001\", description='Regularization  L2: ', style=style),\n",
    "    epochs=IntSlider(min=10, max=100, step=10, value=20, description='Epoch count: ', style=style),\n",
    ")\n",
    "def interactive_learning(n_layers, loss_func, batch_size, lr, l1, l2, \n",
    "                         layer_out_type, epochs,\n",
    "                         layer_size,\n",
    "                         layer1_type, layer2_type, layer3_type, layer4_type):\n",
    "    layer_sizes = [layer_size, layer_size, layer_size, layer_size]\n",
    "    layer_types = [layer1_type, layer2_type, layer3_type, layer4_type]\n",
    "    lr = float(lr)\n",
    "    l1 = float(l1)\n",
    "    l2 = float(l2)\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    if n_layers == 0:\n",
    "        model.add(Dense(len(y_train[0]), activation=layer_out_type, \n",
    "                        input_shape=x_train[0].shape, kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    else:\n",
    "        model.add(Dense(layer_sizes[0], activation=layer_types[0], \n",
    "                        input_shape=x_train[0].shape, kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "        for i in range(1, n_layers):\n",
    "            model.add(Dense(layer_sizes[i], activation=layer_types[i],\n",
    "                           kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "        model.add(Dense(len(y_train[0]), activation=layer_out_type, kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    \n",
    "    model.compile(\n",
    "     optimizer = optimizers.sgd(lr=lr),\n",
    "     loss = loss_func,\n",
    "     metrics = [\"accuracy\"]\n",
    "    )\n",
    "    \n",
    "    history = model.fit(\n",
    "     x_train, y_train,\n",
    "     epochs=epochs,\n",
    "     batch_size=batch_size,\n",
    "     validation_data=(x_test, y_test),\n",
    "     verbose=1\n",
    "    )\n",
    "    \n",
    "    print('Accuracy: ', history.history['val_acc'][-1])\n",
    "    plot_accuracy(history)\n",
    "    #plot_contour_graph(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(x_train[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
